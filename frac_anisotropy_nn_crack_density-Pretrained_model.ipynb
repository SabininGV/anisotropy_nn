{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для воспроизводимости эксперимента:\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesample = 0.004\n",
    "start_time = 1.0\n",
    "end_time = 2.0\n",
    "n_receivers = 80\n",
    "n_timesamples = int((end_time - start_time)/timesample)\n",
    "\n",
    "data = np.empty([1,3,n_receivers,n_timesamples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 1100\n",
      "200 / 1100\n",
      "300 / 1100\n",
      "400 / 1100\n",
      "500 / 1100\n",
      "600 / 1100\n",
      "700 / 1100\n",
      "800 / 1100\n",
      "900 / 1100\n",
      "1000 / 1100\n",
      "1100 / 1100\n"
     ]
    }
   ],
   "source": [
    "n_models = 1100\n",
    "\n",
    "for i in range(n_models):\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(i+1,'/',n_models)\n",
    "    data_Z = pd.read_csv('csv_models_crack_density_Z\\\\model_{}.csv'.format(i+1))\n",
    "    model_gather_Z = np.array(data_Z[data_Z.columns[int(start_time/timesample):int(end_time/timesample)]])\n",
    "    \n",
    "    data_X = pd.read_csv('csv_models_crack_density_X\\\\model_{}.csv'.format(i+1))\n",
    "    model_gather_X = np.array(data_X[data_X.columns[int(start_time/timesample):int(end_time/timesample)]])\n",
    "    \n",
    "    model_zeros = np.zeros(shape=(len(model_gather_X),int(end_time/timesample) - int(start_time/timesample)))\n",
    "    \n",
    "    model_gather = np.vstack(([model_gather_Z],[model_gather_X],[model_zeros]))\n",
    "    model_gather = np.reshape(model_gather,(1,3,n_receivers,n_timesamples))\n",
    "    \n",
    "    data = np.vstack((data,model_gather))\n",
    "    \n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 3, 80, 250)\n",
      "[[[ 8.00617505e-04  1.02273724e-03  1.32891117e-03 ...  7.55271685e-06\n",
      "    4.02872138e-06  5.54585586e-06]\n",
      "  [ 8.12600134e-04  1.03973970e-03  1.34946941e-03 ...  1.83841039e-05\n",
      "    1.61839998e-05  1.07307305e-05]\n",
      "  [ 8.08924204e-04  1.03607518e-03  1.34817208e-03 ...  2.20412476e-05\n",
      "    1.66781392e-05  1.50394571e-05]\n",
      "  ...\n",
      "  [ 1.56030874e-05  4.26389597e-05  6.87852298e-05 ...  4.40955535e-03\n",
      "    3.73170828e-03 -1.93199632e-03]\n",
      "  [-9.79333854e-05 -1.42892852e-04 -2.08559941e-04 ... -7.42730498e-03\n",
      "   -3.09128850e-03  2.96215597e-03]\n",
      "  [-3.46126268e-04 -5.30554680e-04 -6.34867465e-04 ...  4.74087521e-03\n",
      "   -3.35848751e-03 -7.05462322e-03]]\n",
      "\n",
      " [[ 6.99237135e-05  8.44761380e-05  9.41588223e-05 ... -3.16790974e-05\n",
      "   -4.79095761e-05 -4.99428861e-05]\n",
      "  [ 5.52923593e-05  5.61278430e-05  7.12123438e-05 ...  1.61299686e-05\n",
      "   -2.66639108e-05 -7.83016876e-05]\n",
      "  [ 3.67287139e-05  4.03100275e-05  4.04187740e-05 ... -3.74700721e-06\n",
      "   -1.70057610e-05  2.99470703e-05]\n",
      "  ...\n",
      "  [ 4.52201813e-04  2.67484924e-04  5.68898249e-05 ...  1.19028687e-02\n",
      "    4.00425121e-03 -5.96184656e-03]\n",
      "  [ 5.47030475e-04  4.02313890e-04  1.88368023e-04 ... -8.78210366e-03\n",
      "    6.63089007e-03  1.32881366e-02]\n",
      "  [-1.29446325e-05 -2.09916179e-05 -1.10902081e-04 ...  1.93083566e-03\n",
      "   -1.25793330e-02 -9.85430554e-03]]\n",
      "\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.53621181e-02  1.97431569e-02  2.57820613e-02 ... -2.80110109e-04\n",
      "   -3.49616589e-04 -3.19692976e-04]\n",
      "  [ 1.61391646e-02  2.07631765e-02  2.70685240e-02 ... -2.91518528e-05\n",
      "   -7.39406476e-05 -1.84956014e-04]\n",
      "  [ 1.68832980e-02  2.17099586e-02  2.83416090e-02 ...  1.63065969e-04\n",
      "    4.91069422e-05  1.42870947e-05]\n",
      "  ...\n",
      "  [ 6.10024535e-04  1.78496977e-03  2.92125400e-03 ...  1.91565700e-01\n",
      "    1.62107313e-01 -8.40302124e-02]\n",
      "  [-3.48904257e-03 -5.45298574e-03 -8.32149023e-03 ... -3.23654526e-01\n",
      "   -1.34246363e-01  1.30183398e-01]\n",
      "  [-1.39971988e-02 -2.20915981e-02 -2.66697937e-02 ...  2.09266781e-01\n",
      "   -1.46207060e-01 -3.08427176e-01]]\n",
      "\n",
      " [[ 1.25165901e-02  1.61046107e-02  1.84919566e-02 ... -1.25344231e-02\n",
      "   -1.65361819e-02 -1.70375113e-02]\n",
      "  [ 7.36114401e-03  7.51558306e-03  1.03039511e-02 ...  1.21981047e-04\n",
      "   -7.78846213e-03 -1.73336986e-02]\n",
      "  [ 3.97687768e-03  4.52674785e-03  4.54344464e-03 ... -2.23771105e-03\n",
      "   -4.27344260e-03  2.93563309e-03]\n",
      "  ...\n",
      "  [ 1.98903394e-02  1.20796358e-02  3.17467907e-03 ...  5.04078688e-01\n",
      "    1.70087786e-01 -2.51325958e-01]\n",
      "  [ 2.32251160e-02  1.70229615e-02  7.85383055e-03 ... -3.76595894e-01\n",
      "    2.83962592e-01  5.69273853e-01]\n",
      "  [ 1.61080461e-03  1.26128389e-03 -2.64397613e-03 ...  8.60388806e-02\n",
      "   -5.44210141e-01 -4.25848601e-01]]\n",
      "\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# центрирование и нормализация данных\n",
    "for i in range(n_models):\n",
    "    for j in range(2):\n",
    "        data[i,j] = scale(data[i,j], axis=1)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.152476\n",
      "1       0.244568\n",
      "2       0.935301\n",
      "3       0.700633\n",
      "4       0.574909\n",
      "          ...   \n",
      "1095    0.544518\n",
      "1096    0.556375\n",
      "1097    0.963857\n",
      "1098    0.754261\n",
      "1099    0.989970\n",
      "Name: aspect_ratio1, Length: 1100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "frac_params = pd.read_csv('frac_params_crack_density.csv')\n",
    "frac_params['aspect_ratio1'] *= 1000\n",
    "print(frac_params['aspect_ratio1'])\n",
    "#frac_params = np.array(frac_params[['aspect_ratio1']] * 1000) # умножаем, чтобы числа слишком маленькими не были\n",
    "frac_params = np.array(frac_params[['e1_n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(data[:800])\n",
    "X_validation = torch.Tensor(data[800:1100])\n",
    "\n",
    "Y_train = torch.Tensor(frac_params[:800])\n",
    "Y_validation = torch.Tensor(frac_params[800:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "\n",
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        #state_dict['classifier.6.weight'] = state_dict['classifier.6.weight'][0] # !!!!!!!!!1\n",
    "        temp = state_dict['classifier.6.weight'][0]\n",
    "        temp = temp.view(1, temp.size(0))\n",
    "        state_dict['classifier.6.weight'] = torch.tensor(temp, requires_grad=True)\n",
    "        \n",
    "        #state_dict['classifier.6.bias'] = state_dict['classifier.6.bias'][0] # !!!!!!!!!1\n",
    "        temp = state_dict['classifier.6.bias'][0]\n",
    "        temp = [temp]\n",
    "        state_dict['classifier.6.bias'] = torch.tensor(temp, requires_grad=True)\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0327, -0.0062, -0.0040,  ...,  0.0160,  0.0456, -0.0158],\n",
      "        [-0.0281,  0.0393, -0.0035,  ..., -0.0250,  0.0265, -0.0159],\n",
      "        [-0.0019, -0.0004, -0.0081,  ..., -0.0093,  0.0203, -0.0136],\n",
      "        ...,\n",
      "        [-0.0249, -0.0350,  0.0131,  ..., -0.0082,  0.0454, -0.0043],\n",
      "        [ 0.0252, -0.0026, -0.0109,  ..., -0.0091, -0.0615, -0.0009],\n",
      "        [-0.0039,  0.0090, -0.0018,  ...,  0.0229,  0.0042,  0.0185]],\n",
      "       requires_grad=True) \n",
      " torch.Size([1000, 4096])\n",
      "tensor([[ 0.0327, -0.0062, -0.0040,  ...,  0.0160,  0.0456, -0.0158]],\n",
      "       requires_grad=True) \n",
      " torch.Size([1, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "state_dict = load_state_dict_from_url(model_urls['alexnet'], progress=True)\n",
    "print(state_dict['classifier.6.weight'],'\\n',state_dict['classifier.6.weight'].shape)\n",
    "state_dict['classifier.6.weight'] = state_dict['classifier.6.weight'][0]\n",
    "temp = state_dict['classifier.6.weight']\n",
    "temp = temp.view(1, temp.size(0))\n",
    "print(torch.tensor(temp, requires_grad=True),'\\n',torch.tensor(temp, requires_grad=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 5.3252e-02,  5.6475e-02,  1.2015e-02,  1.0475e-02,  1.4073e-02,\n",
      "         2.4921e-02,  4.5943e-02, -1.2418e-02, -5.2491e-02, -1.5580e-02,\n",
      "        -2.1215e-02, -3.3407e-02,  9.5835e-03,  1.8659e-02,  7.1095e-03,\n",
      "        -2.5249e-02, -2.9553e-03,  6.2285e-03, -3.0338e-02,  1.7713e-02,\n",
      "         4.8128e-02,  5.5310e-02,  4.2137e-02, -3.4339e-02,  1.1161e-02,\n",
      "        -3.7005e-02, -3.7998e-02, -2.2497e-02, -1.3564e-02,  1.1125e-01,\n",
      "         3.1010e-02,  6.8569e-03, -1.5973e-02, -9.2437e-03,  4.3681e-02,\n",
      "        -2.6168e-02, -3.0454e-03,  2.6335e-02,  1.0302e-02,  2.9396e-02,\n",
      "        -1.6149e-02,  3.0833e-02,  4.0436e-02,  6.6803e-02,  2.4527e-02,\n",
      "         4.6312e-02,  6.1914e-03,  8.0594e-02,  5.9732e-02,  6.1413e-02,\n",
      "         1.6579e-03,  6.7179e-02, -4.2294e-03, -1.4659e-02, -6.7676e-02,\n",
      "        -8.3818e-03, -5.8036e-02,  8.1914e-03,  3.9684e-02,  2.8477e-02,\n",
      "        -1.2424e-01,  3.9262e-02,  9.1787e-03,  6.8728e-02,  4.0663e-02,\n",
      "        -1.0124e-02,  1.2239e-02, -2.7275e-03, -2.1134e-02,  9.3186e-02,\n",
      "         4.6140e-03,  2.6338e-02,  4.4615e-02, -1.2071e-02, -3.0606e-02,\n",
      "         6.9681e-02,  4.3573e-02, -7.0400e-03,  3.4302e-02,  1.8671e-02,\n",
      "        -2.3980e-03, -7.9588e-03, -2.6701e-02, -2.3112e-02, -2.1024e-02,\n",
      "         7.5927e-03, -4.0854e-02,  9.6504e-02,  1.6273e-02,  6.8265e-02,\n",
      "        -1.2029e-02,  1.8616e-02, -2.3254e-02,  6.6254e-04,  6.5770e-02,\n",
      "         2.0797e-02,  4.6046e-02, -1.2563e-02,  1.5837e-02, -6.2019e-02,\n",
      "         1.6890e-02,  2.9346e-02,  1.2199e-02,  1.1579e-01,  1.8052e-02,\n",
      "         8.3501e-02,  4.6795e-02, -5.9661e-03,  4.3978e-02, -8.9776e-02,\n",
      "        -8.6210e-02,  4.8310e-02, -2.1315e-02,  7.1201e-03, -3.1428e-02,\n",
      "        -2.2256e-02,  9.2478e-02,  5.7419e-02, -2.9094e-04, -1.5966e-02,\n",
      "         9.0139e-02, -1.8068e-02,  5.2080e-02, -1.0922e-02, -5.9916e-02,\n",
      "         6.9528e-02, -4.0415e-03, -2.4078e-02,  1.2984e-02,  8.9963e-03,\n",
      "        -3.2033e-02,  1.7807e-03,  3.9556e-02, -7.1310e-03, -8.6408e-02,\n",
      "        -5.2836e-02, -3.0279e-02, -2.9701e-03,  2.8985e-02, -6.0586e-03,\n",
      "        -1.5632e-02, -1.5263e-02, -1.4647e-02, -6.3525e-02, -3.9613e-02,\n",
      "        -7.7837e-03, -7.8425e-03,  7.1100e-04, -7.7680e-04,  4.9023e-02,\n",
      "        -2.2289e-03,  6.4397e-03, -9.0882e-02,  4.1336e-02, -6.3460e-03,\n",
      "         1.4306e-02,  3.8303e-03, -3.1278e-02, -7.2626e-02, -3.5031e-02,\n",
      "        -2.1359e-02,  6.8324e-02,  4.5042e-02,  2.8514e-02,  3.2959e-02,\n",
      "        -4.6693e-02, -1.0623e-02, -6.0456e-02,  2.3472e-02,  1.9999e-02,\n",
      "         2.5433e-02,  7.6092e-02, -6.2514e-03, -2.5429e-02,  6.6237e-02,\n",
      "        -5.7913e-02, -1.8797e-02,  4.2716e-02,  5.1821e-02, -6.9029e-02,\n",
      "        -1.5346e-02,  2.3568e-02,  5.2703e-02,  5.5551e-02, -8.4720e-03,\n",
      "        -1.2149e-02, -2.7647e-03, -1.4819e-03, -2.3124e-02,  8.9908e-03,\n",
      "        -3.7236e-03,  5.5263e-02,  3.0676e-02, -3.2228e-02, -6.9401e-03,\n",
      "         5.0185e-02,  2.8821e-02,  3.6680e-03, -2.8823e-02,  5.0426e-02,\n",
      "        -1.0344e-01, -2.1276e-03,  4.3640e-02,  3.0670e-02,  1.1708e-02,\n",
      "        -8.2692e-03, -8.7994e-04, -7.9968e-03, -5.8294e-02,  7.0524e-02,\n",
      "        -2.0286e-02,  2.0245e-03, -5.0412e-03, -1.7596e-02,  2.1311e-03,\n",
      "        -1.2316e-02,  1.5342e-02,  3.2776e-02,  5.1759e-03, -4.1486e-02,\n",
      "        -7.3661e-03, -1.9380e-02,  3.3047e-02,  8.3802e-02, -1.9553e-02,\n",
      "         7.2874e-02, -3.5580e-03, -8.1869e-02,  2.6474e-02,  4.9446e-02,\n",
      "         2.9175e-02, -7.6044e-02, -2.3432e-02,  2.2784e-02,  1.0188e-02,\n",
      "         1.0420e-02,  5.3774e-03,  5.4046e-02,  1.4067e-02,  4.0287e-02,\n",
      "        -4.9321e-02, -1.4429e-02, -4.6192e-02, -1.4586e-02, -2.6139e-02,\n",
      "        -4.2562e-04, -5.0145e-02,  3.3987e-02, -5.3159e-02, -5.5430e-02,\n",
      "         3.6954e-03, -1.1041e-03,  2.8349e-02, -4.4211e-02,  5.9482e-02,\n",
      "        -1.5721e-02, -2.6858e-02,  2.9261e-02,  9.5011e-03,  2.4154e-03,\n",
      "         1.3513e-02,  2.8245e-02, -6.4663e-02,  5.3230e-02, -4.3924e-02,\n",
      "         3.4698e-04,  1.7564e-02, -9.1725e-02, -2.3233e-02,  2.2276e-02,\n",
      "         4.0636e-02,  5.2172e-02,  3.5888e-02,  6.8130e-03,  1.0692e-02,\n",
      "         2.1173e-03, -1.7580e-03, -2.7247e-03, -4.8340e-02,  1.3375e-02,\n",
      "        -2.6605e-02,  8.5712e-02, -7.3576e-02,  2.3194e-02,  5.6535e-02,\n",
      "         3.6531e-02,  7.1076e-02, -2.0128e-02, -5.6684e-02,  4.1176e-02,\n",
      "        -1.7057e-02,  1.3072e-03,  1.3561e-02, -8.1499e-02, -1.9378e-02,\n",
      "         3.5581e-02,  3.2518e-02,  6.2056e-02, -3.8972e-02,  4.0444e-02,\n",
      "        -3.7356e-02, -2.5330e-02, -4.5012e-02, -5.6890e-02, -6.5692e-02,\n",
      "         5.4484e-02,  4.5054e-02, -7.4308e-02,  1.1787e-03,  5.3284e-04,\n",
      "        -6.7275e-02, -5.6026e-02, -7.0426e-02,  6.4871e-02,  4.1639e-02,\n",
      "         8.3475e-02,  3.5982e-02,  2.0956e-02,  2.5103e-02, -1.6456e-02,\n",
      "        -1.1024e-02, -2.6935e-02, -9.1414e-03, -5.0469e-02,  5.2238e-02,\n",
      "        -2.6817e-02,  1.4414e-02, -1.0621e-01, -4.6598e-02, -2.5114e-02,\n",
      "         8.4723e-03, -2.5711e-02,  9.3712e-02,  7.2801e-02,  2.5253e-02,\n",
      "         2.1812e-02,  3.3336e-02,  1.6326e-02, -5.2736e-02,  5.5630e-02,\n",
      "        -1.3830e-02, -4.0054e-02,  8.7340e-03,  3.1333e-02,  3.4241e-02,\n",
      "        -5.1627e-02,  2.7252e-02,  2.6041e-02, -5.2250e-02,  2.6162e-02,\n",
      "         5.1007e-02,  2.8195e-02, -2.4470e-02,  1.2946e-02,  5.2765e-02,\n",
      "        -1.8762e-02, -3.1476e-02,  5.5163e-04,  1.0595e-02,  6.4026e-02,\n",
      "        -1.0145e-02,  6.1711e-02,  2.9520e-02,  3.8700e-02,  4.4010e-02,\n",
      "         2.8614e-02,  5.7040e-02,  4.6143e-02, -3.3167e-02,  2.5789e-02,\n",
      "        -9.9446e-03, -3.0128e-03,  9.8479e-03,  3.3981e-02, -1.5649e-02,\n",
      "        -9.9509e-03,  4.9874e-02, -6.3548e-04,  2.8995e-02,  7.9144e-03,\n",
      "        -6.2499e-02, -5.1307e-02,  2.6480e-02,  1.4117e-02, -2.4593e-02,\n",
      "         9.7300e-03, -1.0901e-02,  2.7393e-02,  1.5526e-02,  4.2757e-02,\n",
      "        -4.2605e-02,  1.3845e-02, -1.6240e-02,  4.3815e-02, -2.3015e-03,\n",
      "        -2.2745e-03,  2.7163e-02,  3.5608e-02, -3.9027e-02,  7.4795e-02,\n",
      "         2.9545e-03,  2.4383e-02,  3.8495e-03,  7.3041e-03, -3.5850e-02,\n",
      "         9.0172e-02, -1.9558e-03, -9.6829e-02, -6.6019e-02, -1.2339e-01,\n",
      "         8.5293e-02, -2.8016e-02, -4.2111e-02,  3.4543e-03, -5.9704e-03,\n",
      "        -4.0699e-02,  9.3167e-02,  3.8482e-03, -4.1334e-03,  9.7206e-03,\n",
      "         1.7187e-02, -1.8781e-02, -2.0588e-02,  6.4882e-02,  6.1634e-02,\n",
      "        -4.5338e-05, -4.7090e-02, -1.3213e-01,  2.8466e-02, -2.8057e-02,\n",
      "         5.8503e-02,  6.6895e-02, -3.4372e-02, -1.4239e-02, -3.0599e-02,\n",
      "         1.9456e-02, -3.3238e-02, -2.4988e-02, -9.0367e-05, -4.6692e-02,\n",
      "        -4.8098e-02,  1.9271e-02,  2.4073e-02,  2.2539e-02, -5.8785e-03,\n",
      "         1.5558e-02,  4.0886e-03, -7.8306e-02,  8.6316e-02, -1.4157e-02,\n",
      "         8.7703e-02,  1.1080e-02,  2.4186e-02,  8.9802e-04, -1.2056e-02,\n",
      "        -1.7418e-02, -3.5627e-03, -3.2366e-02, -1.3965e-03, -2.6253e-02,\n",
      "        -2.4457e-02,  1.6563e-02, -1.8416e-02, -1.0767e-01,  9.6398e-03,\n",
      "         4.2801e-02,  6.0262e-02,  3.9423e-02, -7.1208e-02,  3.1756e-02,\n",
      "        -5.8451e-02, -4.1126e-02, -3.6470e-02,  3.2047e-02,  1.0938e-02,\n",
      "         1.5454e-01,  3.8895e-02,  4.0750e-02,  2.8544e-02, -8.7241e-02,\n",
      "         4.4254e-02, -5.8567e-03, -2.4539e-02, -3.7177e-02, -6.1798e-02,\n",
      "         2.9119e-03, -1.5438e-02, -6.9551e-02, -1.3111e-01,  2.5559e-02,\n",
      "         1.5085e-02,  7.0103e-02,  3.3266e-02, -2.6814e-02, -1.1635e-01,\n",
      "        -1.3400e-02,  1.0656e-01, -1.6285e-01,  3.3475e-02, -3.2177e-02,\n",
      "         4.8456e-02, -1.1730e-02, -8.8067e-02, -3.5880e-02,  1.3474e-02,\n",
      "        -2.0326e-02, -1.2884e-01, -5.6742e-02, -6.5963e-02,  1.2026e-02,\n",
      "        -2.5221e-02, -2.3785e-02, -9.6762e-03, -3.7816e-02,  1.9221e-02,\n",
      "         4.8619e-03, -2.4410e-03, -2.6034e-02, -1.9117e-02, -8.2225e-04,\n",
      "         1.7868e-02, -2.7427e-02,  4.1341e-02,  2.4172e-02,  6.8962e-02,\n",
      "         6.3656e-02,  4.3324e-02, -1.6802e-02, -1.7103e-02,  3.2263e-02,\n",
      "        -4.4776e-02, -8.3217e-02, -1.8283e-02,  5.8367e-02,  3.1406e-02,\n",
      "         5.6282e-02, -1.1132e-01,  7.2988e-02, -1.0903e-01,  2.9206e-02,\n",
      "        -2.7821e-02, -1.2398e-01, -2.5645e-02, -5.7258e-02,  8.1258e-03,\n",
      "         2.6332e-02, -2.0495e-02, -4.6250e-02,  2.8908e-03,  9.5556e-02,\n",
      "         4.4201e-02, -2.7812e-03,  2.2221e-03, -4.5316e-02, -4.3130e-02,\n",
      "        -5.8415e-02,  3.2564e-02,  5.7614e-02, -7.8569e-02, -6.7936e-02,\n",
      "        -6.6392e-03,  4.6499e-02, -5.6938e-02,  6.3510e-02,  6.6341e-02,\n",
      "         1.3054e-02, -1.0774e-02, -5.5007e-02,  4.9877e-02,  2.0793e-02,\n",
      "         1.5054e-02, -1.7921e-02, -6.6430e-02,  5.9132e-02,  2.1106e-02,\n",
      "         1.8961e-02, -1.0129e-02,  1.8008e-02, -3.5435e-02,  1.4764e-02,\n",
      "        -7.5889e-03, -8.3661e-02, -5.2211e-02,  6.8491e-02, -2.9039e-02,\n",
      "        -1.9383e-02,  1.5508e-02, -1.8306e-02, -3.6809e-03,  5.0420e-02,\n",
      "        -5.5348e-02,  5.0071e-03,  3.2704e-03, -5.4693e-03,  8.3264e-02,\n",
      "        -2.6980e-02, -3.8524e-02,  7.7673e-02,  3.8679e-02, -4.3476e-02,\n",
      "        -6.3778e-02,  7.1726e-03,  3.6365e-02,  3.5581e-02,  1.8565e-02,\n",
      "        -1.5428e-02,  3.9404e-02,  1.0108e-02,  9.3341e-03, -4.7146e-02,\n",
      "         3.6313e-02,  1.3648e-03,  4.9428e-02,  1.1902e-02, -6.4542e-03,\n",
      "        -4.9254e-02, -1.1963e-01,  9.9042e-02, -2.6934e-02, -7.8272e-02,\n",
      "         5.6361e-03,  1.2645e-02, -3.9618e-03,  2.2964e-02, -3.2064e-02,\n",
      "        -4.6960e-02, -3.3381e-02,  2.9637e-02, -3.6173e-02,  3.0285e-03,\n",
      "         1.7763e-02, -2.4117e-02, -5.6028e-02,  3.5110e-02,  7.2502e-02,\n",
      "        -5.6726e-02, -6.1277e-02, -6.2330e-02, -6.4275e-02, -2.1981e-02,\n",
      "        -1.6378e-02, -7.2263e-02,  3.9917e-02, -9.7765e-02, -4.7685e-02,\n",
      "        -1.9302e-03, -2.4836e-02,  2.4878e-03,  5.6834e-02,  1.0820e-02,\n",
      "        -3.2613e-02,  2.7537e-02,  5.3602e-03,  1.1122e-02, -3.4763e-02,\n",
      "         3.4889e-02,  1.1450e-02, -3.3565e-02,  1.8182e-02, -2.5285e-02,\n",
      "         7.6259e-02, -1.7923e-02,  8.6244e-03, -5.6801e-02, -2.0029e-02,\n",
      "        -7.3464e-03,  7.8287e-03, -2.6822e-02,  4.8273e-03,  9.6238e-02,\n",
      "         1.8904e-02,  3.5164e-02,  7.9271e-02, -1.4469e-02,  8.4794e-02,\n",
      "         2.3145e-02, -4.8635e-02, -1.8980e-02,  1.3211e-02, -1.1367e-02,\n",
      "         5.6345e-02, -3.2129e-02,  9.4927e-03, -4.3672e-02, -5.8385e-02,\n",
      "         2.4477e-02, -4.1123e-02, -1.7410e-02, -2.2212e-02, -4.1425e-02,\n",
      "         4.2289e-02,  8.7909e-02,  2.7870e-02, -7.8393e-02,  6.7135e-04,\n",
      "         3.5587e-03, -2.1712e-02,  2.3001e-02, -8.1032e-02,  7.3319e-03,\n",
      "        -3.3296e-04,  1.6864e-02,  1.7028e-02,  4.5052e-02,  2.4304e-03,\n",
      "        -7.4777e-02,  6.0089e-02,  6.9517e-02, -5.7710e-02,  4.6902e-03,\n",
      "        -3.8819e-03, -5.8210e-02, -1.1185e-03,  9.0919e-02, -8.7339e-03,\n",
      "         6.4967e-02,  1.8759e-02, -5.0487e-02, -4.9778e-02,  4.9940e-02,\n",
      "         2.3460e-02, -1.4869e-02,  7.7824e-03, -2.4576e-02, -4.5487e-02,\n",
      "        -2.6208e-02,  1.3017e-01,  1.6476e-02, -3.0707e-02, -2.2029e-02,\n",
      "        -2.6967e-02,  5.2982e-03,  1.7465e-02, -9.5463e-02, -8.5460e-02,\n",
      "        -2.0266e-03, -2.9333e-03, -6.4850e-02,  7.8749e-02,  1.2722e-01,\n",
      "        -3.0474e-02,  7.9202e-03, -1.4629e-02,  4.9757e-02, -6.1835e-02,\n",
      "         4.2074e-02,  7.3102e-03,  4.7387e-02, -1.0757e-02,  6.5734e-02,\n",
      "        -4.5547e-03,  2.7735e-03,  2.9592e-02,  5.8648e-03, -1.2238e-01,\n",
      "         5.7966e-02,  6.0513e-02, -1.6859e-02, -4.4747e-02, -3.4610e-02,\n",
      "         4.5194e-02,  6.8550e-04, -3.0971e-02,  6.2202e-02, -3.6581e-02,\n",
      "        -2.7143e-02,  1.4357e-02, -2.3183e-03, -1.3557e-03, -2.3419e-02,\n",
      "         7.2945e-02, -1.6167e-02, -6.4322e-02, -6.6394e-02,  8.7976e-03,\n",
      "         5.5808e-03,  3.4428e-02,  4.3121e-02, -9.2526e-02, -6.9069e-02,\n",
      "         7.7242e-03,  5.1836e-03, -5.7449e-02, -2.2806e-02, -4.3065e-02,\n",
      "         1.4340e-01,  3.4542e-02, -3.3381e-02,  6.8073e-02, -4.3122e-02,\n",
      "        -4.7611e-02,  1.2633e-02,  5.0245e-03,  5.3107e-02,  6.6606e-02,\n",
      "         7.7941e-04,  2.1567e-02,  2.8193e-02, -6.4781e-03,  4.6802e-02,\n",
      "        -8.1779e-02,  4.5102e-02,  4.3365e-02,  5.0884e-02,  5.0874e-03,\n",
      "        -4.0991e-02, -5.6369e-02,  4.3932e-02, -1.1832e-02, -3.3235e-02,\n",
      "        -7.4081e-02, -3.1906e-02,  1.6910e-02, -3.5907e-02,  1.9498e-03,\n",
      "         3.7387e-03,  7.7815e-02, -3.8847e-02, -5.2373e-02,  3.9722e-02,\n",
      "        -1.2653e-02, -4.8730e-02,  2.3529e-02,  1.2015e-02, -2.3584e-02,\n",
      "        -4.2143e-03, -7.1829e-02, -8.9830e-02, -1.8455e-02, -5.9362e-02,\n",
      "         1.7717e-02,  5.4384e-02,  3.6537e-03,  5.3803e-03,  7.9031e-02,\n",
      "         2.2240e-02, -1.0549e-02, -4.5449e-03, -2.8834e-02, -1.0402e-02,\n",
      "         2.6980e-03, -4.7863e-02, -7.3498e-04,  8.8465e-02, -2.0006e-02,\n",
      "        -1.0358e-02, -1.3307e-02,  2.0518e-02,  5.8219e-03, -4.0321e-02,\n",
      "        -8.3064e-03, -4.7484e-02, -7.1105e-02,  2.8095e-02,  7.1692e-03,\n",
      "         5.3178e-02, -7.2905e-03, -2.0805e-02, -6.9260e-02,  4.5134e-02,\n",
      "        -1.2814e-02,  1.2746e-02, -4.9280e-03,  2.4691e-02, -3.4422e-02,\n",
      "         6.3144e-02, -2.1781e-02, -5.0597e-02, -7.5548e-02, -3.2391e-02,\n",
      "         1.2470e-02, -6.6609e-02, -3.3134e-02, -2.6591e-02, -4.1465e-02,\n",
      "        -1.8827e-02, -3.0473e-04,  1.5325e-02, -4.7332e-02, -5.5676e-02,\n",
      "         2.1460e-02,  1.9186e-02,  5.3556e-03, -3.1528e-02,  9.7987e-03,\n",
      "        -5.7906e-02, -3.7041e-02,  2.0125e-02, -5.3023e-03,  3.0509e-03,\n",
      "         3.0903e-02, -1.9810e-02, -2.5124e-02,  2.5123e-02,  2.1905e-02,\n",
      "         1.6592e-03,  8.0100e-03,  2.1628e-02, -4.9679e-02, -6.8297e-02,\n",
      "         2.9881e-03,  1.1875e-02, -6.6792e-02,  1.3855e-02,  6.1322e-02,\n",
      "         7.8280e-02,  4.3107e-02, -4.0548e-02,  1.3512e-02,  3.3229e-02,\n",
      "        -5.1434e-02, -7.5863e-02, -3.1879e-02, -1.8831e-02, -5.0711e-03,\n",
      "         4.9725e-02,  8.4448e-03,  3.9326e-02,  7.1417e-02,  4.9369e-02,\n",
      "        -2.7340e-02,  7.9479e-02,  1.8443e-04,  3.4903e-02,  2.6848e-02,\n",
      "         2.9325e-02,  2.4565e-02,  1.3714e-02,  1.0439e-02,  8.2166e-02,\n",
      "         2.2898e-02, -4.9901e-02, -1.2849e-01,  4.4965e-02,  5.4320e-02,\n",
      "         3.0903e-02,  2.7644e-02, -5.0354e-02, -2.5691e-02, -6.2493e-03,\n",
      "         2.7136e-02,  1.1583e-02,  1.8871e-02, -3.5744e-02, -6.0619e-02,\n",
      "        -1.2422e-02, -1.4326e-02, -9.8677e-02, -3.8423e-02, -3.8647e-02,\n",
      "        -9.1581e-02, -4.2368e-02, -4.9885e-02, -1.6033e-02, -4.5562e-02,\n",
      "         2.4515e-02, -2.1699e-02,  3.7827e-03, -3.4757e-02, -4.1276e-02,\n",
      "         3.3561e-02,  5.7945e-02,  6.3927e-02,  7.1584e-03,  2.8452e-02,\n",
      "         1.1123e-01, -2.2850e-02,  1.3239e-02, -8.6398e-02,  4.5526e-02,\n",
      "        -2.9062e-03,  6.4437e-02,  2.3639e-02, -6.8218e-02,  3.5062e-02,\n",
      "        -1.6846e-02,  2.8718e-02,  2.8398e-02, -9.9861e-04, -4.5618e-03,\n",
      "         3.5558e-02,  4.4268e-02,  7.9080e-02,  1.6179e-02, -5.6045e-03,\n",
      "        -3.0647e-02,  2.7647e-02, -1.0381e-01, -3.2340e-02, -8.2798e-03,\n",
      "        -1.2683e-02, -6.8346e-02, -8.5445e-03, -1.1209e-02,  3.1321e-02,\n",
      "        -1.0558e-02, -2.0959e-02,  3.0059e-02, -5.2112e-02,  2.3731e-02],\n",
      "       requires_grad=True) \n",
      " torch.Size([1000])\n",
      "tensor([0.0533], requires_grad=True) \n",
      " torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "state_dict = load_state_dict_from_url(model_urls['alexnet'], progress=True)\n",
    "print(state_dict['classifier.6.bias'],'\\n',state_dict['classifier.6.bias'].shape)\n",
    "temp = state_dict['classifier.6.bias'][0]\n",
    "temp = [temp]\n",
    "state_dict['classifier.6.bias'] = torch.tensor(temp, requires_grad=True)\n",
    "print(state_dict['classifier.6.bias'],'\\n',state_dict['classifier.6.bias'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.0,2.0,3.0], requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "#neural_net = FracAnisotropyNet(4,6,2)\n",
    "neural_net = alexnet(pretrained=True)\n",
    "neural_net = neural_net.to(device)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(neural_net.parameters(), lr=3.0e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 1 :\n",
      "\tTrain Loss:\t 124.98528 \n",
      "\tTest Loss:\t 0.06599144\n",
      "epoch # 2 :\n",
      "\tTrain Loss:\t 0.0339041 \n",
      "\tTest Loss:\t 0.003511682\n",
      "epoch # 3 :\n",
      "\tTrain Loss:\t 0.0029079935 \n",
      "\tTest Loss:\t 0.0008652348\n",
      "epoch # 4 :\n",
      "\tTrain Loss:\t 0.0012177973 \n",
      "\tTest Loss:\t 0.0008331233\n",
      "epoch # 5 :\n",
      "\tTrain Loss:\t 0.000989259 \n",
      "\tTest Loss:\t 0.0008363974\n",
      "epoch # 6 :\n",
      "\tTrain Loss:\t 0.00092391414 \n",
      "\tTest Loss:\t 0.0008344212\n",
      "epoch # 7 :\n",
      "\tTrain Loss:\t 0.00090225635 \n",
      "\tTest Loss:\t 0.00083241786\n",
      "epoch # 8 :\n",
      "\tTrain Loss:\t 0.0008847224 \n",
      "\tTest Loss:\t 0.0008381263\n",
      "epoch # 9 :\n",
      "\tTrain Loss:\t 0.0008993291 \n",
      "\tTest Loss:\t 0.00083966524\n",
      "epoch # 10 :\n",
      "\tTrain Loss:\t 0.00087488344 \n",
      "\tTest Loss:\t 0.00083872606\n",
      "epoch # 11 :\n",
      "\tTrain Loss:\t 0.00089320156 \n",
      "\tTest Loss:\t 0.00083530106\n",
      "epoch # 12 :\n",
      "\tTrain Loss:\t 0.000889927 \n",
      "\tTest Loss:\t 0.0008354015\n",
      "epoch # 13 :\n",
      "\tTrain Loss:\t 0.0008521693 \n",
      "\tTest Loss:\t 0.0008301225\n",
      "epoch # 14 :\n",
      "\tTrain Loss:\t 0.0008820505 \n",
      "\tTest Loss:\t 0.0008312681\n",
      "epoch # 15 :\n",
      "\tTrain Loss:\t 0.00087648694 \n",
      "\tTest Loss:\t 0.00083157263\n",
      "epoch # 16 :\n",
      "\tTrain Loss:\t 0.0008776336 \n",
      "\tTest Loss:\t 0.0008328419\n",
      "epoch # 17 :\n",
      "\tTrain Loss:\t 0.0008686036 \n",
      "\tTest Loss:\t 0.00084312336\n",
      "epoch # 18 :\n",
      "\tTrain Loss:\t 0.00087102654 \n",
      "\tTest Loss:\t 0.0008382308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-5926684c06ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_init\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_init\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;31m#loss_value = weighted_loss(pred,y_batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-471568929fd0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "N = len(X_train)\n",
    "\n",
    "test_loss_history = []\n",
    "train_loss_history = []\n",
    "\n",
    "X_validation = X_validation.to(device)\n",
    "Y_validation = Y_validation.to(device)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    order = np.random.permutation(N)\n",
    "  \n",
    "    loss_sum = 0.0\n",
    "    for batch_init in range(0,N,batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        neural_net.train()\n",
    "    \n",
    "        X_batch = X_train[order[batch_init:batch_init+batch_size]].to(device)\n",
    "        y_batch = Y_train[order[batch_init:batch_init+batch_size]].to(device)\n",
    "    \n",
    "        pred = neural_net.forward(X_batch)\n",
    "        #loss_value = weighted_loss(pred,y_batch)\n",
    "        loss_value = loss(pred,y_batch)\n",
    "        loss_sum += loss_value\n",
    "        loss_value.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "    neural_net.eval()\n",
    "    pred = neural_net.forward(X_validation)\n",
    "  \n",
    "    tr_l = loss_sum/(N/batch_size)\n",
    "    te_l = loss(pred,Y_validation)\n",
    "    train_loss_history.append(tr_l.data.cpu())\n",
    "    test_loss_history.append(te_l.data.cpu())\n",
    "  \n",
    "    print('epoch #', epoch+1,':\\n\\tTrain Loss:\\t',tr_l.data.cpu().numpy(),'\\n\\tTest Loss:\\t',te_l.data.cpu().numpy())\n",
    "\n",
    "educ_time = datetime.datetime.now() - start_time\n",
    "print('Time elapsed:', educ_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "num = 30\n",
    "def moving_average(a, n=num): # среднее скользящее среднее\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history[10:])\n",
    "plt.plot(test_loss_history[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_train = moving_average(train_loss_history)\n",
    "avg_loss_test = moving_average(test_loss_history)\n",
    "plt.plot(avg_loss_train[10:])\n",
    "plt.plot(avg_loss_test[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Loss: ', avg_loss_train[-1])\n",
    "print('Test Loss:  ', avg_loss_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = neural_net.forward(X_validation)\n",
    "pred = pred.data.cpu().numpy()\n",
    "y_val = Y_validation.data.cpu().numpy()\n",
    "print('Predicted\\tReal value\\tDifference')\n",
    "sum_dn = 0.0\n",
    "sum_e1_n = 0.0\n",
    "sum_e1_t = 0.0\n",
    "sum_asp = 0.0\n",
    "sum_asp_real = 0.0\n",
    "sum_e1_n_real = 0.0\n",
    "sum_e1_t_real = 0.0\n",
    "sum_dn_real = 0.0\n",
    "sum_dn_sq = 0.0\n",
    "for i in range(300):\n",
    "    dif = abs(pred[i]-y_val[i])\n",
    "    print(pred[i],'\\t',y_val[i],'\\t',dif)\n",
    "    sum_e1_n += dif[0]\n",
    "    #sum_e1_t += dif[1]\n",
    "    #sum_asp += dif[0]\n",
    "    #sum_asp_real += y_val[i][0]\n",
    "    sum_e1_n_real += y_val[i][0]\n",
    "    #sum_e1_t_real += y_val[i][1]\n",
    "    #sum_dn += dif[0]\n",
    "    #sum_dn_sq += dif[0]**2\n",
    "    #sum_dn_real == y_val[i][0]\n",
    "    \n",
    "#mean_e1_n_real = sum_e1_n_real/300\n",
    "#mean_e1_t_real = sum_e1_t_real/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean e1_n difference: ', sum_e1_n/300)\n",
    "#print('Mean e1_t difference: ', sum_e1_t/300)\n",
    "#print('Mean aspect ratio difference: ', sum_asp/300)\n",
    "\n",
    "#print(mean_asp_real)\n",
    "print('\\nRelative e1_n accuracy: ', sum_e1_n/sum_e1_n_real)\n",
    "#print('Relative e1_t accuracy: ', sum_e1_t/300/mean_e1_t_real)\n",
    "#print('Relative aspect ratio accuracy: ', sum_asp/sum_asp_real)\n",
    "#print('Mean dn difference: ', sum_dn/300)\n",
    "#print('dn MSE: ', math.sqrt(sum_dn_sq/300))\n",
    "#print('\\nRelative dn accuracy: ', sum_dn/sum_dn_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs((pred-Y_validation).data.cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
